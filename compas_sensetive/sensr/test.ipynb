{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597189222984",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import linear_model\n",
    "import utils\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "plt.ioff()\n",
    "import sys\n",
    "from data_preprocess import get_data\n",
    "import json\n",
    "import compas_data\n",
    "#tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "def sample_perturbation(data_point, regularizer = 20, learning_rate = 3e-2, num_steps = 200):\n",
    "    \"\"\"\n",
    "    Calculates ratio between perturbed loss and original loss\n",
    "\n",
    "    parameters: \n",
    "        data_point: tuple of x, y\n",
    "            x: tensor of shape (d, )\n",
    "            y: one-hot encoded tensor of shape (2, )\n",
    "        regularizer (float): regularizer constant for fair metric\n",
    "        learning_rate (float): step size for gradient ascend\n",
    "        num_steps (int): number of steps in gradient ascend\n",
    "\n",
    "    return:\n",
    "        float; ratio of entropy losses for perturbed and original sample\n",
    "    \"\"\"\n",
    "    x, y = data_point\n",
    "    x = tf.reshape(x, (1, -1))\n",
    "    y = tf.reshape(y, (1, -1))\n",
    "    x_start = x\n",
    "    for i in range(num_steps):\n",
    "        with tf.GradientTape() as g:\n",
    "            g.watch(x)\n",
    "            prob = graph(x)\n",
    "            perturb = utils.unprotected_direction(x-x_start, sensetive_directions)\n",
    "            loss = utils.EntropyLoss(y, prob)  - regularizer  * tf.norm(perturb)**2\n",
    "\n",
    "        gradient = g.gradient(loss, x)\n",
    "        x = x + learning_rate * gradient/((i+1) ** (2/3))\n",
    "        print(loss)\n",
    "\n",
    "    return_loss = utils.EntropyLoss(y, graph(x)) / utils.EntropyLoss(y, graph(x_start))\n",
    "    print('done')\n",
    "    return return_loss.numpy()\n",
    "\n",
    "def SimpleDense(variable):\n",
    "    w, b = variable\n",
    "    w = tf.cast(w, dtype = tf.float32)\n",
    "    b = tf.cast(b, dtype = tf.float32)\n",
    "    return lambda x: tf.matmul(x, w) + b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(5278, 8)\n['sex', 'race', 'priors_count', 'age_cat=25 to 45', 'age_cat=Greater than 45', 'age_cat=Less than 25', 'c_charge_degree=F', 'c_charge_degree=M']\n"
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "train_size=7751 should be either positive and smaller than the number of samples 5278 or a float in the (0, 1) range",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-03114631a54b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mseed_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m7751\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m43757\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_sex_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_sex_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_race_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_race_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_orig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompas_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_compas_train_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/individual-fairness-testing/compas_sensetive/sensr/compas_data.py\u001b[0m in \u001b[0;36mget_compas_train_test\u001b[0;34m(pct, random_state)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;31m# dataset_orig_train, dataset_orig_test = dataset_orig.split([pct], shuffle=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_orig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_orig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2120\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2121\u001b[0m     n_train, n_test = _validate_shuffle_split(n_samples, test_size, train_size,\n\u001b[0;32m-> 2122\u001b[0;31m                                               default_test_size=0.25)\n\u001b[0m\u001b[1;32m   2123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2124\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   1761\u001b[0m         raise ValueError('train_size={0} should be either positive and smaller'\n\u001b[1;32m   1762\u001b[0m                          \u001b[0;34m' than the number of samples {1} or a float in the '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1763\u001b[0;31m                          '(0, 1) range'.format(train_size, n_samples))\n\u001b[0m\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1765\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtrain_size_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: train_size=7751 should be either positive and smaller than the number of samples 5278 or a float in the (0, 1) range"
     ]
    }
   ],
   "source": [
    "seed_data, seed_model = 7751, 43757\n",
    "x_train, x_test, y_train, y_test, y_sex_train, y_sex_test, y_race_train, y_race_test, _ = compas_data.get_compas_train_test(seed_data)\n",
    "\n",
    "\n",
    "\n",
    "sensetive_directions = []\n",
    "protected_regression = linear_model.LogisticRegression(fit_intercept = True)\n",
    "protected_regression.fit(x_test.numpy(), y_sex_test)\n",
    "sensetive_directions.append(protected_regression.coef_.reshape((-1,)))\n",
    "protected_regression.fit(x_test.numpy(), y_race_test)\n",
    "sensetive_directions.append(protected_regression.coef_.reshape((-1,)))\n",
    "sensetive_directions = np.array(sensetive_directions)\n",
    "\n",
    "sensetive_directions = scipy.linalg.orth(sensetive_directions.T).T\n",
    "for i, s in enumerate(sensetive_directions):\n",
    "        #while np.linalg.norm(s) != 1:\n",
    "    s = s/ np.linalg.norm(s)\n",
    "    sensetive_directions[i] = s\n",
    "sensetive_directions = tf.cast(sensetive_directions, dtype = tf.float32)\n",
    "\n",
    "\n",
    "with open(f'models/data_{seed_data}_{seed_model}.txt', 'r') as f:\n",
    "    weight = json.load(f)\n",
    "\n",
    "weights = [np.array(w) for w in weight]\n",
    "\n",
    "def graph(x):\n",
    "    layer1 = SimpleDense([weights[0], weights[1]])\n",
    "    layer2 = SimpleDense([weights[2], weights[3]])\n",
    "    out = tf.nn.relu(layer1(x))\n",
    "    out = layer2(out)\n",
    "    prob = tf.nn.softmax(out)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tf.Tensor(0.5782235, shape=(), dtype=float32)\ntf.Tensor(0.5778041, shape=(), dtype=float32)\ntf.Tensor(0.5692901, shape=(), dtype=float32)\ntf.Tensor(0.5582235, shape=(), dtype=float32)\ntf.Tensor(0.56039625, shape=(), dtype=float32)\ntf.Tensor(0.57307905, shape=(), dtype=float32)\ntf.Tensor(0.58264685, shape=(), dtype=float32)\ntf.Tensor(0.5858533, shape=(), dtype=float32)\ntf.Tensor(0.5868089, shape=(), dtype=float32)\ntf.Tensor(0.5873734, shape=(), dtype=float32)\ntf.Tensor(0.5878782, shape=(), dtype=float32)\ntf.Tensor(0.58835214, shape=(), dtype=float32)\ntf.Tensor(0.5888, shape=(), dtype=float32)\ntf.Tensor(0.5892248, shape=(), dtype=float32)\ntf.Tensor(0.58962965, shape=(), dtype=float32)\ntf.Tensor(0.59001666, shape=(), dtype=float32)\ntf.Tensor(0.5903878, shape=(), dtype=float32)\ntf.Tensor(0.59074444, shape=(), dtype=float32)\ntf.Tensor(0.5910883, shape=(), dtype=float32)\ntf.Tensor(0.59142, shape=(), dtype=float32)\ntf.Tensor(0.5917409, shape=(), dtype=float32)\ntf.Tensor(0.59205174, shape=(), dtype=float32)\ntf.Tensor(0.59235334, shape=(), dtype=float32)\ntf.Tensor(0.59264636, shape=(), dtype=float32)\ntf.Tensor(0.5929314, shape=(), dtype=float32)\ntf.Tensor(0.59320897, shape=(), dtype=float32)\ntf.Tensor(0.59347945, shape=(), dtype=float32)\ntf.Tensor(0.5937436, shape=(), dtype=float32)\ntf.Tensor(0.59400153, shape=(), dtype=float32)\ntf.Tensor(0.5942536, shape=(), dtype=float32)\ntf.Tensor(0.59450024, shape=(), dtype=float32)\ntf.Tensor(0.59474164, shape=(), dtype=float32)\ntf.Tensor(0.59497815, shape=(), dtype=float32)\ntf.Tensor(0.59521, shape=(), dtype=float32)\ntf.Tensor(0.5954373, shape=(), dtype=float32)\ntf.Tensor(0.5956605, shape=(), dtype=float32)\ntf.Tensor(0.5958796, shape=(), dtype=float32)\ntf.Tensor(0.59609497, shape=(), dtype=float32)\ntf.Tensor(0.59630644, shape=(), dtype=float32)\ntf.Tensor(0.5965146, shape=(), dtype=float32)\ntf.Tensor(0.5967193, shape=(), dtype=float32)\ntf.Tensor(0.59692085, shape=(), dtype=float32)\ntf.Tensor(0.59711915, shape=(), dtype=float32)\ntf.Tensor(0.5973145, shape=(), dtype=float32)\ntf.Tensor(0.59750694, shape=(), dtype=float32)\ntf.Tensor(0.5976966, shape=(), dtype=float32)\ntf.Tensor(0.5978836, shape=(), dtype=float32)\ntf.Tensor(0.598068, shape=(), dtype=float32)\ntf.Tensor(0.59825, shape=(), dtype=float32)\ntf.Tensor(0.59842944, shape=(), dtype=float32)\ndone\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1.0355872"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "lr = 5e-2\n",
    "data = x_test[0], y_test[0]\n",
    "sample_perturbation(data, regularizer=50,\\\n",
    "             learning_rate=lr, num_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}