{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of individual fairness testing for SenSR fitted on Adult data\n",
    "\n",
    "We present a small scale demo for SenSR fitted on Adult data. We shall use SenSR weights fitted on Adult data. \n",
    "\n",
    "Let's install and load the requred models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install aif360\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sensr.adult_modified import preprocess_adult_data\n",
    "from sklearn import linear_model\n",
    "import sensr.utils as utils\n",
    "import scipy\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from functools import partial\n",
    "from scipy.stats import norm\n",
    "import sensr.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the seed for train-test split and initialization of model fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = np.load('seeds.npy')\n",
    "run = 0\n",
    "seed_data, seed_model = seeds[run, 0], seeds[run, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing \n",
    "\n",
    "Let's load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_orig_train, dataset_orig_test = preprocess_adult_data(seed = seed_data)\n",
    "x_unprotected_train, x_protected_train = dataset_orig_train.features[:, :39], dataset_orig_train.features[:, 39:]\n",
    "x_unprotected_test, x_protected_test = dataset_orig_test.features[:, :39], dataset_orig_test.features[:, 39:]\n",
    "y_train, y_test = dataset_orig_train.labels.reshape((-1,)), dataset_orig_test.labels.reshape((-1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit logistic regression for gender and race on the other covariates to get the sensetive directions. We then extract orthonormal basis from them. These will be used to project out sensitive directions from features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensetive_directions = []\n",
    "protected_regression = linear_model.LogisticRegression(fit_intercept = True)\n",
    "protected_regression.fit(x_unprotected_test, x_protected_test[:, 0])\n",
    "sensetive_directions.append(protected_regression.coef_.reshape((-1,)))\n",
    "protected_regression.fit(x_unprotected_test, x_protected_test[:, 1])\n",
    "sensetive_directions.append(protected_regression.coef_.reshape((-1,)))\n",
    "sensetive_directions = np.array(sensetive_directions)\n",
    "\n",
    "sensetive_directions = scipy.linalg.orth(sensetive_directions.T).T\n",
    "for i, s in enumerate(sensetive_directions):\n",
    "    while np.linalg.norm(s) != 1:\n",
    "        s = s/ np.linalg.norm(s)\n",
    "    sensetive_directions[i] = s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables are casted to proper tensor objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = y_train.astype('int32'), y_test.astype('int32')\n",
    "x_unprotected_train, x_unprotected_test = tf.cast(x_unprotected_train, dtype = tf.float32), tf.cast(x_unprotected_test, dtype = tf.float32)\n",
    "y_train, y_test = tf.one_hot(y_train, 2), tf.one_hot(y_test, 2)\n",
    "sensetive_directions = tf.cast(sensetive_directions, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload model\n",
    "\n",
    "Let's load the weights and biases of the corresponding run of experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./sensr/models/data_{seed_data}_{seed_model}.txt', 'r') as f:\n",
    "    weight = json.load(f)\n",
    "weights = [np.array(w) for w in weight]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build the graph using pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for boulding layer with given weight and bias\n",
    "def SimpleDense(variable):\n",
    "    w, b = variable\n",
    "    w = tf.cast(w, dtype = tf.float32)\n",
    "    b = tf.cast(b, dtype = tf.float32)\n",
    "    return lambda x: tf.matmul(x, w) + b\n",
    "\n",
    "# We use prefitted weights and biases to build the graph\n",
    "def graph(x):\n",
    "    layer1 = SimpleDense([weights[0], weights[1]])\n",
    "    layer2 = SimpleDense([weights[2], weights[3]])\n",
    "    out = tf.nn.relu(layer1(x))\n",
    "    out = layer2(out)\n",
    "    prob = tf.nn.softmax(out)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient flow attack and hypothesis testing\n",
    "\n",
    "We define the required function which performs gradient-flow-attack and returns ratio of perturbed loss and original loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_perturbation(data_point, regularizer = 100, learning_rate = 5e-2, num_steps = 200):\n",
    "    \"\"\"\n",
    "    Calculates ratio between perturbed loss and original loss\n",
    "\n",
    "    parameters: \n",
    "        data_point: tuple of x, y\n",
    "            x: tensor of shape (d, )\n",
    "            y: one-hot encoded tensor of shape (2, )\n",
    "        regularizer (float): regularizer constant for fair metric\n",
    "        learning_rate (float): step size for gradient ascend\n",
    "        num_steps (int): number of steps in gradient ascend\n",
    "\n",
    "    return:\n",
    "        float; ratio of entropy losses for perturbed and original sample\n",
    "    \"\"\"\n",
    "    x, y = data_point\n",
    "    x = tf.reshape(x, (1, -1))\n",
    "    y = tf.reshape(y, (1, -1))\n",
    "    x_start = x\n",
    "    for i in range(num_steps):\n",
    "        with tf.GradientTape() as g:\n",
    "            g.watch(x)\n",
    "            prob = graph(x)\n",
    "            perturb = utils.unprotected_direction(x-x_start, sensetive_directions)\n",
    "            loss = utils.EntropyLoss(y, prob)  - regularizer  * tf.norm(perturb)**2\n",
    "\n",
    "        gradient = g.gradient(loss, x)\n",
    "        x = x + learning_rate * gradient / ((i + 1) ** (2/3))\n",
    "\n",
    "    return_loss = utils.EntropyLoss(y, graph(x)) / utils.EntropyLoss(y, graph(x_start))\n",
    "    \n",
    "    return return_loss.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demo purpose we perform gradient flow attack only on first 20 test points. Readers are welcome to perform it on their liking of test points. We create zipped sequence of data points for first 20 test points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "end = 20\n",
    "data_points = zip(x_unprotected_test[start:end], y_test[start:end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now setup some experimental parameters and extract a partial function using them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularizer = 50\n",
    "learning_rate = 1e-2\n",
    "num_steps = 200\n",
    "sample_perturb = partial(sample_perturbation, regularizer = regularizer, learning_rate = \\\n",
    "                        learning_rate, num_steps = num_steps)\n",
    "test_ratios = map(sample_perturb, data_points)\n",
    "test_ratios = list(test_ratios)\n",
    "test_ratios = np.array(test_ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we calculate the lower bound and p-value for the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the proposed test, lower bound is 1.0109767625867034 and p-value is 1.0.\n",
      "\n",
      "The test is not rejected at a level 0.05 and we conclude the model is \u001b[1;40;47mindividually fair.\n"
     ]
    }
   ],
   "source": [
    "test_ratios = test_ratios[np.isfinite(test_ratios)]\n",
    "lower_bound = np.mean(test_ratios) - 1.645*np.std(test_ratios)/np.sqrt(test_ratios.shape[0])\n",
    "t = (np.mean(test_ratios)-1.25)/np.std(test_ratios)\n",
    "t *= np.sqrt(test_ratios.shape[0])\n",
    "pval = 1- norm.cdf(t)\n",
    "print(f'For the proposed test, lower bound is {lower_bound} and\\\n",
    " p-value is {pval}.\\n')\n",
    "decision = 'rejected' if pval < 0.05 else 'not rejected'\n",
    "if pval < 0.05:\n",
    "    print('The test is rejected at a level 0.05 and\\\n",
    " we conclude the model is not \\033[1;40;47mindividually fair.')\n",
    "else:\n",
    "    print('The test is not rejected at a\\\n",
    " level 0.05 and we conclude the model is \\033[1;40;47mindividually fair.')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some fairness measures\n",
    "\n",
    "Now we calculate some fairness measures for the fitted model. First we get the predictions on the test data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = graph(x_unprotected_test)\n",
    "y_pred = tf.argmax(prob, axis = 1)\n",
    "y_pred = y_pred.numpy()\n",
    "gender = dataset_orig_test.features[:, 39]\n",
    "race = dataset_orig_test.features[:, 40]\n",
    "y_test = dataset_orig_test.labels.reshape((-1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we calculate sevaral fairness measures for gender and race. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;40;47mMeasures for gender:\u001b[1;40;0m\n",
      "Accuracy is 0.751797\n",
      "Balanced accuracy is 0.750635\n",
      "Gap RMS is 0.04686660860680571\n",
      "Mean absolute gap is 0.04467711097540024\n",
      "Max gap is 0.05883460924293629\n",
      "Average odds difference is -0.014157\n",
      "Equal opportunity difference is 0.030520\n",
      "Statistical parity difference is -0.142075\n",
      "\n",
      "\u001b[1;40;47mMeasures for race:\u001b[1;40;0m\n",
      "Accuracy is 0.751797\n",
      "Balanced accuracy is 0.750635\n",
      "Gap RMS is 0.05802546350787034\n",
      "Mean absolute gap is 0.05786025174847749\n",
      "Max gap is 0.06223582975669539\n",
      "Average odds difference is -0.057860\n",
      "Equal opportunity difference is -0.062236\n",
      "Statistical parity difference is -0.099100\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1;40;47mMeasures for gender:\\033[1;40;0m')\n",
    "_ = metrics.group_metrics(y_test, y_pred, gender, label_good=1)\n",
    "\n",
    "print('\\n\\033[1;40;47mMeasures for race:\\033[1;40;0m')\n",
    "_ = metrics.group_metrics(y_test, y_pred, race, label_good=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464bit48aa32fa6dba4f1bbd692e320b15fd93"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
