{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of individual fairness testing for SenSR and reduction\n",
    "\n",
    "We present a small scale demo for SenSR fitted on Adult data. We shall use SenSR weights fitted on Adult data. \n",
    "\n",
    "Let's install and load the requred models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install aif360\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sensr.adult_modified import preprocess_adult_data\n",
    "from sklearn import linear_model\n",
    "import sensr.utils as utils\n",
    "import scipy\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from functools import partial\n",
    "from scipy.stats import norm\n",
    "import sensr.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the seed for train-test split and initialization of model fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = np.load('seeds.npy')\n",
    "run = 0\n",
    "seed_data, seed_model = seeds[run, 0], seeds[run, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing \n",
    "\n",
    "Let's load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_orig_train, dataset_orig_test = preprocess_adult_data(seed = seed_data)\n",
    "x_unprotected_train, x_protected_train = dataset_orig_train.features[:, :39], dataset_orig_train.features[:, 39:]\n",
    "x_unprotected_test, x_protected_test = dataset_orig_test.features[:, :39], dataset_orig_test.features[:, 39:]\n",
    "y_train, y_test = dataset_orig_train.labels.reshape((-1,)), dataset_orig_test.labels.reshape((-1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit logistic regression for gender and race on the other covariates to get the sensetive directions. We then extract orthonormal basis from them. These will be used to project out sensitive directions from features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensetive_directions = []\n",
    "protected_regression = linear_model.LogisticRegression(fit_intercept = True)\n",
    "protected_regression.fit(x_unprotected_test, x_protected_test[:, 0])\n",
    "sensetive_directions.append(protected_regression.coef_.reshape((-1,)))\n",
    "protected_regression.fit(x_unprotected_test, x_protected_test[:, 1])\n",
    "sensetive_directions.append(protected_regression.coef_.reshape((-1,)))\n",
    "sensetive_directions = np.array(sensetive_directions)\n",
    "\n",
    "sensetive_directions = scipy.linalg.orth(sensetive_directions.T).T\n",
    "for i, s in enumerate(sensetive_directions):\n",
    "    while np.linalg.norm(s) != 1:\n",
    "        s = s/ np.linalg.norm(s)\n",
    "    sensetive_directions[i] = s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables are casted to proper tensor objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = y_train.astype('int32'), y_test.astype('int32')\n",
    "x_unprotected_train, x_unprotected_test = tf.cast(x_unprotected_train, dtype = tf.float32), tf.cast(x_unprotected_test, dtype = tf.float32)\n",
    "y_train, y_test = tf.one_hot(y_train, 2), tf.one_hot(y_test, 2)\n",
    "sensetive_directions = tf.cast(sensetive_directions, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SenSR\n",
    "\n",
    "Here we present the demo for SenSR model. We provide both the options of fitting the model or using pre-trained model (training SenSR takes a while). \n",
    "\n",
    "### Training SenSR\n",
    "\n",
    "SenSR codes are written in tensorflow1. So, we load the tensorflow1 compatable modules in tensorflow2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip this if you want to use pretrained model\n",
    "import tensorflow.compat.v1 as tf\n",
    "from sensr.train_clp_adult import train_fair_nn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def run_sensr(seed_data, seed_model):\n",
    "    \n",
    "\n",
    "    #seed_data = int(float(sys.argv[1]))\n",
    "    #seed_model = int(float(sys.argv[2]))\n",
    "\n",
    "    dataset_orig_train, dataset_orig_test = preprocess_adult_data(seed = seed_data)\n",
    "\n",
    "    all_train, all_test = dataset_orig_train.features, dataset_orig_test.features\n",
    "    y_train, y_test = dataset_orig_train.labels.reshape((-1,)), dataset_orig_test.labels.reshape((-1,))\n",
    "    y_train, y_test = y_train.astype('int32'), y_test.astype('int32')\n",
    "\n",
    "    x_train = np.delete(all_train, [dataset_orig_test.feature_names.index(feat) for feat in ['sex_ Male', 'race_ White']], axis = 1)\n",
    "    x_test = np.delete(all_test, [dataset_orig_test.feature_names.index(feat) for feat in ['sex_ Male', 'race_ White']], axis = 1)\n",
    "\n",
    "    group_train = dataset_orig_train.features[:, [dataset_orig_test.feature_names.index(feat) for feat in ['sex_ Male', 'race_ White']]]\n",
    "    group_test = dataset_orig_test.features[:, [dataset_orig_test.feature_names.index(feat) for feat in ['sex_ Male', 'race_ White']]]\n",
    "    group_names = ['Gender', 'Race']\n",
    "\n",
    "    one_hot = OneHotEncoder(sparse=False)\n",
    "    one_hot.fit(y_train.reshape(-1,1))\n",
    "    names_income = one_hot.categories_\n",
    "    y_train = one_hot.transform(y_train.reshape(-1,1))\n",
    "    y_test = one_hot.transform(y_test.reshape(-1,1))\n",
    "\n",
    "    sensitive_directions = []\n",
    "    for y_protected in group_train.T:\n",
    "    \tlr = linear_model.LogisticRegression(solver='liblinear', fit_intercept=True)\n",
    "    \tlr.fit(x_train, y_protected)\n",
    "    \tsensitive_directions.append(lr.coef_.flatten())\n",
    "\n",
    "    sensitive_directions = np.array(sensitive_directions)\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    fair_info = [group_train, group_test, group_names, sensitive_directions]\n",
    "    weights, train_logits, test_logits, _, variables = train_fair_nn(x_train, y_train, tf_prefix='sensr', adv_epoch_full=50, l2_attack=0.0001,\n",
    "                                          adv_epoch=10, ro=0.001, adv_step=10., plot=False, fair_info=fair_info, balance_batch=True, \n",
    "                                          X_test = x_test, X_test_counter=None, y_test = y_test, lamb_init=2., \n",
    "                                          n_units=[100], l2_reg=0, epoch=20000, batch_size=1000, lr=1e-5, lambda_clp=0.,\n",
    "                                          fair_start=0., counter_init=False, seed=None)\n",
    "\n",
    "    \n",
    "\n",
    "    return weight\n",
    "weights = run_sensr(seed_data, seed_model)\n",
    "\n",
    "# Reloading tensorflow 2 modules \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload pre-trained weights\n",
    "\n",
    "Let's load the weights and biases of the corresponding run of experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./sensr/models/data_{seed_data}_{seed_model}.txt', 'r') as f:\n",
    "    weight = json.load(f)\n",
    "weights = [np.array(w) for w in weight]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the graph \n",
    "\n",
    "Now we build the graph using pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for boulding layer with given weight and bias\n",
    "def SimpleDense(variable):\n",
    "    w, b = variable\n",
    "    w = tf.cast(w, dtype = tf.float32)\n",
    "    b = tf.cast(b, dtype = tf.float32)\n",
    "    return lambda x: tf.matmul(x, w) + b\n",
    "\n",
    "# We use prefitted weights and biases to build the graph\n",
    "def graph_sensr(x):\n",
    "    layer1 = SimpleDense([weights[0], weights[1]])\n",
    "    layer2 = SimpleDense([weights[2], weights[3]])\n",
    "    out = tf.nn.relu(layer1(x))\n",
    "    out = layer2(out)\n",
    "    prob = tf.nn.softmax(out)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient flow attack and hypothesis testing\n",
    "\n",
    "We define the required function which performs gradient-flow-attack and returns ratio of perturbed loss and original loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_perturbation(data_point, regularizer = 100, learning_rate = 5e-2, num_steps = 200):\n",
    "    \"\"\"\n",
    "    Calculates ratio between perturbed loss and original loss\n",
    "\n",
    "    parameters: \n",
    "        data_point: tuple of x, y\n",
    "            x: tensor of shape (d, )\n",
    "            y: one-hot encoded tensor of shape (2, )\n",
    "        regularizer (float): regularizer constant for fair metric\n",
    "        learning_rate (float): step size for gradient ascend\n",
    "        num_steps (int): number of steps in gradient ascend\n",
    "\n",
    "    return:\n",
    "        float; ratio of entropy losses for perturbed and original sample\n",
    "    \"\"\"\n",
    "    x, y = data_point\n",
    "    x = tf.reshape(x, (1, -1))\n",
    "    y = tf.reshape(y, (1, -1))\n",
    "    x_start = x\n",
    "    for i in range(num_steps):\n",
    "        with tf.GradientTape() as g:\n",
    "            g.watch(x)\n",
    "            prob = graph_sensr(x)\n",
    "            perturb = utils.unprotected_direction(x-x_start, sensetive_directions)\n",
    "            loss = utils.EntropyLoss(y, prob)  - regularizer  * tf.norm(perturb)**2\n",
    "\n",
    "        gradient = g.gradient(loss, x)\n",
    "        x = x + learning_rate * gradient\n",
    "\n",
    "    return_loss = utils.EntropyLoss(y, graph_sensr(x)) / utils.EntropyLoss(y, graph_sensr(x_start))\n",
    "    \n",
    "    return return_loss.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demo purpose we perform gradient flow attack only on first 20 test points. Readers are welcome to perform it on their liking of test points. We create zipped sequence of data points for first 20 test points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "end = 20\n",
    "data_points = zip(x_unprotected_test[start:end], y_test[start:end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now setup some experimental parameters and extract a partial function using them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularizer = 50\n",
    "learning_rate = 1e-2\n",
    "num_steps = 200\n",
    "sample_perturb = partial(sample_perturbation, regularizer = regularizer, learning_rate = \\\n",
    "                        learning_rate, num_steps = num_steps)\n",
    "test_ratios = map(sample_perturb, data_points)\n",
    "test_ratios = list(test_ratios)\n",
    "test_ratios = np.array(test_ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we calculate the lower bound and p-value for the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the proposed test, lower bound is 1.0385039692301912 and p-value is 1.0.\n",
      "\n",
      "The test is not rejected at a level 0.05 and we conclude the model is \u001b[1;40;47mindividually fair.\n"
     ]
    }
   ],
   "source": [
    "test_ratios = test_ratios[np.isfinite(test_ratios)]\n",
    "lower_bound = np.mean(test_ratios) - 1.645*np.std(test_ratios)/np.sqrt(test_ratios.shape[0])\n",
    "t = (np.mean(test_ratios)-1.25)/np.std(test_ratios)\n",
    "t *= np.sqrt(test_ratios.shape[0])\n",
    "pval = 1- norm.cdf(t)\n",
    "print(f'For the proposed test, lower bound is {lower_bound} and\\\n",
    " p-value is {pval}.\\n')\n",
    "decision = 'rejected' if pval < 0.05 else 'not rejected'\n",
    "if pval < 0.05:\n",
    "    print('The test is rejected at a level 0.05 and\\\n",
    " we conclude the model is not \\033[1;40;47mindividually fair.')\n",
    "else:\n",
    "    print('The test is not rejected at a\\\n",
    " level 0.05 and we conclude the model is \\033[1;40;47mindividually fair.')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some fairness measures\n",
    "\n",
    "Now we calculate some fairness measures for the fitted model. First we get the predictions on the test data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = graph_sensr(x_unprotected_test)\n",
    "y_pred = tf.argmax(prob, axis = 1)\n",
    "y_pred = y_pred.numpy()\n",
    "gender = dataset_orig_test.features[:, 39]\n",
    "race = dataset_orig_test.features[:, 40]\n",
    "labels_test = dataset_orig_test.labels.reshape((-1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we calculate sevaral fairness measures for gender and race. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;40;47mMeasures for gender:\u001b[1;40;0m\n",
      "Accuracy is 0.751797\n",
      "Balanced accuracy is 0.750635\n",
      "Gap RMS is 0.04686660860680571\n",
      "Mean absolute gap is 0.04467711097540024\n",
      "Max gap is 0.05883460924293629\n",
      "Average odds difference is -0.014157\n",
      "Equal opportunity difference is 0.030520\n",
      "Statistical parity difference is -0.142075\n",
      "\n",
      "\u001b[1;40;47mMeasures for race:\u001b[1;40;0m\n",
      "Accuracy is 0.751797\n",
      "Balanced accuracy is 0.750635\n",
      "Gap RMS is 0.05802546350787034\n",
      "Mean absolute gap is 0.05786025174847749\n",
      "Max gap is 0.06223582975669539\n",
      "Average odds difference is -0.057860\n",
      "Equal opportunity difference is -0.062236\n",
      "Statistical parity difference is -0.099100\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1;40;47mMeasures for gender:\\033[1;40;0m')\n",
    "_ = metrics.group_metrics(labels_test, y_pred, gender, label_good=1)\n",
    "\n",
    "print('\\n\\033[1;40;47mMeasures for race:\\033[1;40;0m')\n",
    "_ = metrics.group_metrics(labels_test, y_pred, race, label_good=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduction\n",
    "\n",
    "Here we present testing demo for reduction method. As before we are providing both the options of training the model or using pre-tarined model. \n",
    "\n",
    "### Training reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from fairlearn.reductions import ExponentiatedGradient\n",
    "from fairlearn.reductions import DemographicParity, TruePositiveRateDifference, ErrorRateRatio, EqualizedOdds\n",
    "from reduction.metrics import group_metrics\n",
    "constraints = {'TPRD': TruePositiveRateDifference,\n",
    "               'ERR': ErrorRateRatio,\n",
    "               'DP': DemographicParity,\n",
    "               'EO': EqualizedOdds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip this if you want to use pre-trained model\n",
    "def extract_weights(run):\n",
    "    data_seed = seeds[run, 0]\n",
    "    \n",
    "    dataset_orig_train, dataset_orig_test = preprocess_adult_data(seed = data_seed)\n",
    "\n",
    "    all_train, all_test = dataset_orig_train.features, dataset_orig_test.features\n",
    "    y_train, y_test = dataset_orig_train.labels.reshape((-1,)), dataset_orig_test.labels.reshape((-1,))\n",
    "    y_train, y_test = y_train.astype('int32'), y_test.astype('int32')\n",
    "\n",
    "    x_train = np.delete(all_train, [dataset_orig_test.feature_names.index(feat) for feat in ['sex_ Male', 'race_ White']], axis = 1)\n",
    "    x_test = np.delete(all_test, [dataset_orig_test.feature_names.index(feat) for feat in ['sex_ Male', 'race_ White']], axis = 1)\n",
    "\n",
    "    group_train = dataset_orig_train.features[:, [dataset_orig_test.feature_names.index(feat) for feat in ['sex_ Male', 'race_ White']]]\n",
    "    group_test = dataset_orig_test.features[:, [dataset_orig_test.feature_names.index(feat) for feat in ['sex_ Male', 'race_ White']]]\n",
    "    group_train_cross = group_train[:,0] + group_train[:,1]*2\n",
    "    group_test_cross = group_test[:,0] + group_test[:,1]*2\n",
    "\n",
    "    ## Train reductions\n",
    "    eps = 0.03\n",
    "    c = 'EO'\n",
    "    constraint = constraints[c]()\n",
    "    classifier = LogisticRegression(solver='liblinear', fit_intercept=True, class_weight='balanced')\n",
    "    mitigator = ExponentiatedGradient(classifier, constraint, eps=eps)\n",
    "    mitigator.fit(x_train, y_train, sensitive_features=group_train_cross)\n",
    "    y_pred_mitigated = mitigator.predict(x_test)\n",
    "    print('\\nFair on all test')\n",
    "    _ = group_metrics(y_test, y_pred_mitigated, group_test[:,0], label_protected=0, label_good=1)\n",
    "\n",
    "\n",
    "    ens_weights = []\n",
    "    coefs = []\n",
    "    intercepts = []\n",
    "\n",
    "    for t, w_t in enumerate(mitigator._weights.index):\n",
    "        if mitigator._weights[w_t] > 0:\n",
    "            coefs.append(mitigator._predictors[t].coef_.flatten())\n",
    "            intercepts.append(mitigator._predictors[t].intercept_[0])\n",
    "            ens_weights.append(mitigator._weights[w_t])\n",
    "\n",
    "    ens_weight = [e.tolist() for e in ens_weights]\n",
    "    coef = [c.tolist() for c in coefs]\n",
    "    intercept = [i.tolist() for i in intercepts]\n",
    "\n",
    "    data = {'ens_weights': ens_weight, 'coefs': coef, 'intercepts': intercept}\n",
    "    return data\n",
    "\n",
    "data = extract_weights(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./reduction/models/data_{seed_data}.txt', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the graph\n",
    "\n",
    "We now build the graph with extracted weights, intercepts and coefficients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = data['coefs']\n",
    "intercept = data['intercepts']\n",
    "weight = data['ens_weights']\n",
    "coefs = [tf.cast(c, dtype = tf.float32) for c in coef]\n",
    "intercepts = [tf.cast(c, dtype = tf.float32) for c in intercept]\n",
    "weights = [tf.cast(c, dtype = tf.float32) for c in weight]\n",
    "\n",
    "def graph_reduction(x):\n",
    "    global coefs, intercepts, weights\n",
    "    n, _ = x.shape\n",
    "    prob = tf.zeros([n, 1], dtype = tf.float32)\n",
    "    for coef, intercept, weight in zip(coefs, intercepts, weights):\n",
    "        coef = tf.reshape(coef, [-1, 1])\n",
    "        model_logit = x @ coef + intercept\n",
    "        model_prob = tf.exp(model_logit) / (1 + tf.exp(model_logit))\n",
    "        prob += model_prob * weight\n",
    "\n",
    "    return tf.concat([1-prob, prob], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient flow attack and hypothesis testing\n",
    "\n",
    "We now perform gradient flow attack on reduction model. As before, we first define the function for gradient flow attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_perturbation(data_point, regularizer = 100, learning_rate = 5e-2, num_steps = 200):\n",
    "    \"\"\"\n",
    "    Calculates ratio between perturbed loss and original loss\n",
    "\n",
    "    parameters: \n",
    "        data_point: tuple of x, y\n",
    "            x: tensor of shape (d, )\n",
    "            y: one-hot encoded tensor of shape (2, )\n",
    "        regularizer (float): regularizer constant for fair metric\n",
    "        learning_rate (float): step size for gradient ascend\n",
    "        num_steps (int): number of steps in gradient ascend\n",
    "\n",
    "    return:\n",
    "        float; ratio of entropy losses for perturbed and original sample\n",
    "    \"\"\"\n",
    "    x, y = data_point\n",
    "    x = tf.reshape(x, (1, -1))\n",
    "    y = tf.reshape(y, (1, -1))\n",
    "    x_start = x\n",
    "    for i in range(num_steps):\n",
    "        with tf.GradientTape() as g:\n",
    "            g.watch(x)\n",
    "            prob = graph_reduction(x)\n",
    "            perturb = utils.unprotected_direction(x-x_start, sensetive_directions)\n",
    "            loss = utils.EntropyLoss(y, prob)  - regularizer  * tf.norm(perturb)**2\n",
    "\n",
    "        gradient = g.gradient(loss, x)\n",
    "        x = x + learning_rate * gradient\n",
    "\n",
    "    return_loss = utils.EntropyLoss(y, graph_reduction(x)) / utils.EntropyLoss(y, graph_reduction(x_start))\n",
    "    \n",
    "    return return_loss.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demonstration purpose we perform attact on first 20 sample points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "end = 20\n",
    "data_points = zip(x_unprotected_test[start:end], y_test[start:end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We steup parameters for gradient flow attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularizer = 50\n",
    "learning_rate = 1e-2\n",
    "num_steps = 200\n",
    "sample_perturb = partial(sample_perturbation, regularizer = regularizer, learning_rate = \\\n",
    "                        learning_rate, num_steps = num_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient flow attack is performed on the selected sample points. Along with the lower bound and decision is given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the proposed test, lower bound is 2.4446973404799226 and p-value is 6.068317737195628e-09.\n",
      "\n",
      "The test is rejected at a level 0.05 and we conclude the model is not individually fair.\n"
     ]
    }
   ],
   "source": [
    "test_ratio = map(sample_perturb, data_points)\n",
    "test_ratio = list(test_ratio)\n",
    "test_ratio = np.array(test_ratio)\n",
    "test_ratio = test_ratio[np.isfinite(test_ratio)]\n",
    "lower_bound = np.mean(test_ratio) - 1.645*np.std(test_ratio)/np.sqrt(test_ratio.shape[0])\n",
    "t = (np.mean(test_ratio)-1.25)/np.std(test_ratio)\n",
    "t *= np.sqrt(test_ratio.shape[0])\n",
    "pval = 1- norm.cdf(t)\n",
    "print(f'For the proposed test, lower bound is {lower_bound} and\\\n",
    " p-value is {pval}.\\n')\n",
    "decision = 'rejected' if pval < 0.05 else 'not rejected'\n",
    "if pval < 0.05:\n",
    "    print('The test is rejected at a level 0.05 and\\\n",
    " we conclude the model is not individually fair.')\n",
    "else:\n",
    "    print('The test is not rejected at a\\\n",
    " level 0.05 and we conclude the model is individually fair.')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some fairness measures\n",
    "\n",
    "Now we calculate some fairness measures for the fitted model. First we get the predictions on the test data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;40;47mMeasures for gender:\u001b[1;40;0m\n",
      "Accuracy is 0.819790\n",
      "Balanced accuracy is 0.796751\n",
      "Gap RMS is 0.05525612347933615\n",
      "Mean absolute gap is 0.05459925122749115\n",
      "Max gap is 0.06309401122180236\n",
      "Average odds difference is 0.008495\n",
      "Equal opportunity difference is 0.063094\n",
      "Statistical parity difference is -0.145235\n",
      "\n",
      "\u001b[1;40;47mMeasures for race:\u001b[1;40;0m\n",
      "Accuracy is 0.819790\n",
      "Balanced accuracy is 0.796751\n",
      "Gap RMS is 0.039352036125304454\n",
      "Mean absolute gap is 0.03899846673206153\n",
      "Max gap is 0.04426176795425629\n",
      "Average odds difference is -0.038998\n",
      "Equal opportunity difference is -0.044262\n",
      "Statistical parity difference is -0.087918\n"
     ]
    }
   ],
   "source": [
    "prob = graph_reduction(x_unprotected_test)\n",
    "y_pred = tf.argmax(prob, axis = 1)\n",
    "y_pred = y_pred.numpy()\n",
    "gender = dataset_orig_test.features[:, 39]\n",
    "race = dataset_orig_test.features[:, 40]\n",
    "labels_test = dataset_orig_test.labels.reshape((-1,))\n",
    "\n",
    "print('\\033[1;40;47mMeasures for gender:\\033[1;40;0m')\n",
    "_ = metrics.group_metrics(labels_test, y_pred, gender, label_good=1)\n",
    "\n",
    "print('\\n\\033[1;40;47mMeasures for race:\\033[1;40;0m')\n",
    "_ = metrics.group_metrics(labels_test, y_pred, race, label_good=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464bit48aa32fa6dba4f1bbd692e320b15fd93"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
