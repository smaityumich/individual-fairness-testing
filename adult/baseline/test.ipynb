{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitd090249c0cf5439884290524b93fde75",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from adult_modified import preprocess_adult_data\n",
    "from sklearn import linear_model\n",
    "import utils\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "plt.ioff()\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_perturbation(data_point, graph,  regularizer = 20, learning_rate = 3e-2, num_steps = 200):\n",
    "    \"\"\"\n",
    "    Calculates ratio between perturbed loss and original loss\n",
    "\n",
    "    parameters: \n",
    "        data_point: tuple of x, y\n",
    "            x: tensor of shape (d, )\n",
    "            y: one-hot encoded tensor of shape (2, )\n",
    "        regularizer (float): regularizer constant for fair metric\n",
    "        learning_rate (float): step size for gradient ascend\n",
    "        num_steps (int): number of steps in gradient ascend\n",
    "\n",
    "    return:\n",
    "        float; ratio of entropy losses for perturbed and original sample\n",
    "    \"\"\"\n",
    "    x, y = data_point\n",
    "    x = tf.reshape(x, (1, -1))\n",
    "    y = tf.reshape(y, (1, -1))\n",
    "    x_start = x\n",
    "    for _ in range(num_steps):\n",
    "        with tf.GradientTape() as g:\n",
    "            g.watch(x)\n",
    "            prob = graph(x)\n",
    "            perturb = utils.unprotected_direction(x-x_start, sensetive_directions)\n",
    "            loss = utils.EntropyLoss(y, prob)  - regularizer  * tf.norm(perturb)**2\n",
    "\n",
    "        gradient = g.gradient(loss, x)\n",
    "        x = x + learning_rate * gradient\n",
    "\n",
    "    return_loss = utils.EntropyLoss(y, graph(x)) / utils.EntropyLoss(y, graph(x_start))\n",
    "    \n",
    "    return return_loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = np.load('../seeds.npy')\n",
    "seed_data, seed_model = seeds[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "iters = 20\n",
    "dataset_orig_train, dataset_orig_test = preprocess_adult_data(seed = seed_data)\n",
    "\n",
    "x_unprotected_train, x_protected_train = dataset_orig_train.features[:, :39], dataset_orig_train.features[:, 39:]\n",
    "x_unprotected_test, x_protected_test = dataset_orig_test.features[:, :39], dataset_orig_test.features[:, 39:]\n",
    "y_train, y_test = dataset_orig_train.labels.reshape((-1,)), dataset_orig_test.labels.reshape((-1,))\n",
    "\n",
    "\n",
    "\n",
    "sensetive_directions = []\n",
    "protected_regression = linear_model.LogisticRegression(fit_intercept = True)\n",
    "protected_regression.fit(x_unprotected_test, x_protected_test[:, 0])\n",
    "sensetive_directions.append(protected_regression.coef_.reshape((-1,)))\n",
    "protected_regression.fit(x_unprotected_test, x_protected_test[:, 1])\n",
    "sensetive_directions.append(protected_regression.coef_.reshape((-1,)))\n",
    "sensetive_directions = np.array(sensetive_directions)\n",
    "\n",
    "sensetive_directions = scipy.linalg.orth(sensetive_directions.T).T\n",
    "for i, s in enumerate(sensetive_directions):\n",
    "    while np.linalg.norm(s) != 1:\n",
    "        s = s/ np.linalg.norm(s)\n",
    "    sensetive_directions[i] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x14ce09ed0> and <tensorflow.python.keras.layers.core.Dense object at 0x14ce51310>).\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "y_train, y_test = y_train.astype('int32'), y_test.astype('int32')\n",
    "x_unprotected_train, x_unprotected_test = tf.cast(x_unprotected_train, dtype = tf.float32), tf.cast(x_unprotected_test, dtype = tf.float32)\n",
    "y_train, y_test = tf.one_hot(y_train, 2), tf.one_hot(y_test, 2)\n",
    "sensetive_directions = tf.cast(sensetive_directions, dtype = tf.float32)\n",
    "\n",
    "\n",
    "\n",
    "graph = tf.keras.models.load_model(f'graphs/graph_{seed_data}_{seed_model}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x14cdce9d0>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9045, 2), dtype=float32, numpy=\n",
       "array([[0.4662716 , 0.5337285 ],\n",
       "       [0.63381535, 0.3661847 ],\n",
       "       [0.89712983, 0.1028702 ],\n",
       "       ...,\n",
       "       [0.56902593, 0.43097407],\n",
       "       [0.97452027, 0.02547975],\n",
       "       [0.9970921 , 0.00290783]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "graph(x_unprotected_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_point = x_unprotected_test[1], y_test[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(39,), dtype=float32, numpy=\n",
       " array([-0.49579805, -0.43515417,  0.26477247, -0.2192382 , -0.24259609,\n",
       "         0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "data_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "19.128063"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "sample_perturbation(data_point, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}