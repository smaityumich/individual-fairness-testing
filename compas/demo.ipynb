{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of individual fairness testing for SenSR and reduction using **COMPAS** data\n",
    "\n",
    "We present a small scale demo for SenSR fitted on COMPAS data. We shall use SenSR weights fitted on COMPAS data. \n",
    "\n",
    "Let's install and load the requred models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install aif360\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from compas_data import get_compas_train_test\n",
    "from sklearn import linear_model\n",
    "import sensr.utils as utils\n",
    "import scipy\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from functools import partial\n",
    "from scipy.stats import norm\n",
    "import sensr.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the seed for train-test split and initialization of model fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = np.load('seeds.npy')\n",
    "run = 0\n",
    "seed_data, seed_model = seeds[run, 0], seeds[run, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing \n",
    "\n",
    "Let's load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5278, 8)\n",
      "['sex', 'race', 'priors_count', 'age_cat=25 to 45', 'age_cat=Greater than 45', 'age_cat=Less than 25', 'c_charge_degree=F', 'c_charge_degree=M']\n",
      "sex\n",
      "race\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test, y_sex_train, y_sex_test,\\\n",
    "        y_race_train, y_race_test, _ = get_compas_train_test(random_state = seed_data)\n",
    "group_train, group_test = np.copy(x_train[:, :2]), np.copy(x_test[:, :2])\n",
    "y_sex_train, y_sex_test, y_race_train, y_race_test = np.copy(y_sex_train), np.copy(y_sex_test),\\\n",
    "        np.copy(y_race_train), np.copy(y_race_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit logistic regression for gender and race on the other covariates to get the sensetive directions. We then extract orthonormal basis from them. These will be used to project out sensitive directions from features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitive_dir(x, gender, race):\n",
    "    d = x.shape[1]\n",
    "    sensetive_directions = []\n",
    "    protected_regression = linear_model.LogisticRegression(fit_intercept = True)\n",
    "    protected_regression.fit(x[:, 2:], gender)\n",
    "    a = protected_regression.coef_.reshape((-1,))\n",
    "    a = np.concatenate(([0, 0], a), axis=0)\n",
    "    sensetive_directions.append(a)\n",
    "    protected_regression.fit(x[:,2:], race)\n",
    "    a = protected_regression.coef_.reshape((-1,))\n",
    "    a = np.concatenate(([0, 0], a), axis=0)\n",
    "    sensetive_directions.append(a)\n",
    "    a, b = np.zeros((d,)), np.zeros((d,))\n",
    "    a[0], b[1] = 1, 1\n",
    "    sensetive_directions.append(a)\n",
    "    sensetive_directions.append(b)\n",
    "    sensetive_directions = np.array(sensetive_directions)\n",
    "\n",
    "    # Extrancting orthornormal basis for sensitive directions\n",
    "    sensetive_basis = scipy.linalg.orth(sensetive_directions.T).T\n",
    "    for i, s in enumerate(sensetive_basis):\n",
    "        #while np.linalg.norm(s) != 1:\n",
    "        s = s/ np.linalg.norm(s)\n",
    "        sensetive_basis[i] = s\n",
    "\n",
    "    return sensetive_directions, sensetive_basis\n",
    "\n",
    "\n",
    "_, sensetive_basis = sensitive_dir(x_test, y_sex_test, y_race_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables are casted to proper tensor objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.astype('int32')\n",
    "x_test = tf.cast(x_test, dtype = tf.float32)\n",
    "y_test = tf.one_hot(y_test, 2)\n",
    "sensetive_basis = tf.cast(sensetive_basis, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SenSR\n",
    "\n",
    "Here we present the demo for SenSR model. We provide both the options of fitting the model or using pre-trained model (training SenSR takes a while). \n",
    "\n",
    "### Training SenSR\n",
    "\n",
    "SenSR codes are written in tensorflow1. So, we load the tensorflow1 compatable modules in tensorflow2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip this if you want to use pretrained model\n",
    "import tensorflow.compat.v1 as tf\n",
    "from sensr.train_clp_adult import train_fair_nn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def run_sensr(seed_data, seed_model):\n",
    "    \n",
    "\n",
    "    x_train, x_test, y_train, y_test, y_sex_train, y_sex_test,\\\n",
    "        y_race_train, y_race_test, _ = compas.get_compas_train_test(random_state = seed_data)\n",
    "    group_train, group_test = np.copy(x_train[:, :2]), np.copy(x_test[:, :2])\n",
    "    y_sex_train, y_sex_test, y_race_train, y_race_test = np.copy(y_sex_train), np.copy(y_sex_test),\\\n",
    "        np.copy(y_race_train), np.copy(y_race_test)\n",
    "    \n",
    "    \n",
    "    group_names = ['sex', 'race']\n",
    "\n",
    "\n",
    "    one_hot = OneHotEncoder(sparse=False)\n",
    "    one_hot.fit(y_train.reshape(-1,1))\n",
    "    names_income = one_hot.categories_\n",
    "    y_train = one_hot.transform(y_train.reshape(-1,1))\n",
    "    y_test = one_hot.transform(y_test.reshape(-1,1))\n",
    " \n",
    "    sensetive_directions, _ = sensitive_dir(x_train, y_sex_train, y_race_train)\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    fair_info = [group_train, group_test, group_names, sensetive_directions]\n",
    "    weights, train_logits, test_logits, _, variables = train_fair_nn(x_train, y_train,\\\n",
    "         tf_prefix='sensr', adv_epoch_full=8,l2_attack=0.0001, adv_epoch=10, ro=0.001,\\\n",
    "         adv_step=0.1, plot=save_model, fair_info=fair_info, balance_batch=True, \\\n",
    "         X_test = x_test, X_test_counter=None, y_test = y_test, lamb_init=2., n_units=[100],\\\n",
    "         l2_reg=0, epoch=16000, batch_size=1000, lr=10e-5, lambda_clp=0.,\\\n",
    "         fair_start=0., counter_init=False, seed=seed_model)\n",
    "\n",
    "    \n",
    "\n",
    "    return weight\n",
    "weights = run_sensr(seed_data, seed_model)\n",
    "\n",
    "# Reloading tensorflow 2 modules \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload pre-trained weights\n",
    "\n",
    "Let's load the weights and biases of the corresponding run of experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./sensr/models/data_{seed_data}_{seed_model}.txt', 'r') as f:\n",
    "    weight = json.load(f)\n",
    "weights = [np.array(w) for w in weight]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the graph \n",
    "\n",
    "Now we build the graph using pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for boulding layer with given weight and bias\n",
    "def SimpleDense(variable):\n",
    "    w, b = variable\n",
    "    w = tf.cast(w, dtype = tf.float32)\n",
    "    b = tf.cast(b, dtype = tf.float32)\n",
    "    return lambda x: tf.matmul(x, w) + b\n",
    "\n",
    "# We use prefitted weights and biases to build the graph\n",
    "def graph_sensr(x):\n",
    "    layer1 = SimpleDense([weights[0], weights[1]])\n",
    "    layer2 = SimpleDense([weights[2], weights[3]])\n",
    "    out = tf.nn.relu(layer1(x))\n",
    "    out = layer2(out)\n",
    "    prob = tf.nn.softmax(out)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient flow attack and hypothesis testing\n",
    "\n",
    "We define the required function which performs gradient-flow-attack and returns ratio of perturbed loss and original loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_perturbation(data_point, regularizer = 100, learning_rate = 5e-2, num_steps = 200):\n",
    "    \"\"\"\n",
    "    Calculates ratio between perturbed loss and original loss\n",
    "\n",
    "    parameters: \n",
    "        data_point: tuple of x, y\n",
    "            x: tensor of shape (d, )\n",
    "            y: one-hot encoded tensor of shape (2, )\n",
    "        regularizer (float): regularizer constant for fair metric\n",
    "        learning_rate (float): step size for gradient ascend\n",
    "        num_steps (int): number of steps in gradient ascend\n",
    "\n",
    "    return:\n",
    "        float; ratio of entropy losses for perturbed and original sample\n",
    "    \"\"\"\n",
    "    x, y = data_point\n",
    "    x = tf.reshape(x, (1, -1))\n",
    "    y = tf.reshape(y, (1, -1))\n",
    "    x_start = x\n",
    "    for i in range(num_steps):\n",
    "        with tf.GradientTape() as g:\n",
    "            g.watch(x)\n",
    "            prob = graph_sensr(x)\n",
    "            perturb = utils.unprotected_direction(x-x_start, sensetive_basis)\n",
    "            loss = utils.EntropyLoss(y, prob)  - regularizer  * tf.norm(perturb)**2\n",
    "\n",
    "        gradient = g.gradient(loss, x)\n",
    "        x = x + learning_rate * gradient\n",
    "\n",
    "    return_loss = utils.EntropyLoss(y, graph_sensr(x)) / utils.EntropyLoss(y, graph_sensr(x_start))\n",
    "    \n",
    "    return return_loss.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demo purpose we perform gradient flow attack only on first 20 test points. Readers are welcome to perform it on their liking of test points. We create zipped sequence of data points for first 20 test points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "end = 20\n",
    "data_points = zip(x_test[start:end], y_test[start:end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now setup some experimental parameters and extract a partial function using them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularizer = 100\n",
    "learning_rate = 1e-2\n",
    "num_steps = 200\n",
    "sample_perturb = partial(sample_perturbation, regularizer = regularizer, learning_rate = \\\n",
    "                        learning_rate, num_steps = num_steps)\n",
    "test_ratios = map(sample_perturb, data_points)\n",
    "test_ratios = list(test_ratios)\n",
    "test_ratios = np.array(test_ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we calculate the lower bound and p-value for the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the proposed test, lower bound is 1.043219325729754 and p-value is 0.9999359875463081.\n",
      "\n",
      "The test is not rejected at a level 0.05 and we conclude the model is \u001b[1;40;47mindividually fair.\n"
     ]
    }
   ],
   "source": [
    "test_ratios = test_ratios[np.isfinite(test_ratios)]\n",
    "lower_bound = np.mean(test_ratios) - 1.645*np.std(test_ratios)/np.sqrt(test_ratios.shape[0])\n",
    "t = (np.mean(test_ratios)-1.25)/np.std(test_ratios)\n",
    "t *= np.sqrt(test_ratios.shape[0])\n",
    "pval = 1- norm.cdf(t)\n",
    "print(f'For the proposed test, lower bound is {lower_bound} and\\\n",
    " p-value is {pval}.\\n')\n",
    "decision = 'rejected' if pval < 0.05 else 'not rejected'\n",
    "if pval < 0.05:\n",
    "    print('The test is rejected at a level 0.05 and\\\n",
    " we conclude the model is not \\033[1;40;47mindividually fair.')\n",
    "else:\n",
    "    print('The test is not rejected at a\\\n",
    " level 0.05 and we conclude the model is \\033[1;40;47mindividually fair.')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some fairness measures\n",
    "\n",
    "Now we calculate some fairness measures for the fitted model. First we get the predictions on the test data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = graph_sensr(x_test)\n",
    "y_pred = tf.argmax(prob, axis = 1)\n",
    "y_pred = y_pred.numpy()\n",
    "gender = y_sex_test\n",
    "race = y_race_test\n",
    "labels_test = y_test.numpy()[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we calculate sevaral fairness measures for gender and race. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;40;47mMeasures for gender:\u001b[1;40;0m\n",
      "Accuracy is 0.613636\n",
      "Balanced accuracy is 0.611854\n",
      "Gap RMS is 0.012150305376121497\n",
      "Mean absolute gap is 0.011789878620164812\n",
      "Max gap is 0.014727340595201699\n",
      "Average odds difference is -0.011790\n",
      "Equal opportunity difference is -0.008852\n",
      "Statistical parity difference is 0.024008\n",
      "\n",
      "\u001b[1;40;47mMeasures for race:\u001b[1;40;0m\n",
      "Accuracy is 0.613636\n",
      "Balanced accuracy is 0.611854\n",
      "Gap RMS is 0.2319540377864503\n",
      "Mean absolute gap is 0.22779090159377147\n",
      "Max gap is 0.2715399678299181\n",
      "Average odds difference is 0.227791\n",
      "Equal opportunity difference is 0.271540\n",
      "Statistical parity difference is 0.240416\n",
      "\n",
      "\n",
      "*Accuracy and Balanced accuracy are measuring performance irrespective of the protected attribute.\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1;40;47mMeasures for gender:\\033[1;40;0m')\n",
    "_ = metrics.group_metrics(labels_test, y_pred, gender, label_good=1)\n",
    "\n",
    "print('\\n\\033[1;40;47mMeasures for race:\\033[1;40;0m')\n",
    "_ = metrics.group_metrics(labels_test, y_pred, race, label_good=1)\n",
    "\n",
    "print('\\n\\n*Accuracy and Balanced accuracy are measuring performance irrespective of the protected attribute.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduction\n",
    "\n",
    "Here we present testing demo for reduction method. As before we are providing both the options of training the model or using pre-tarined model. \n",
    "\n",
    "### Training reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from fairlearn.reductions import ExponentiatedGradient\n",
    "from fairlearn.reductions import DemographicParity, TruePositiveRateDifference, ErrorRateRatio, EqualizedOdds\n",
    "from reduction.metrics import group_metrics\n",
    "constraints = {'TPRD': TruePositiveRateDifference,\n",
    "               'ERR': ErrorRateRatio,\n",
    "               'DP': DemographicParity,\n",
    "               'EO': EqualizedOdds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5278, 8)\n",
      "['sex', 'race', 'priors_count', 'age_cat=25 to 45', 'age_cat=Greater than 45', 'age_cat=Less than 25', 'c_charge_degree=F', 'c_charge_degree=M']\n",
      "sex\n",
      "race\n",
      "\n",
      "Fair on all test\n",
      "Accuracy is 0.650568\n",
      "Balanced accuracy is 0.646626\n",
      "Gap RMS is 0.061104992926792515\n",
      "Mean absolute gap is 0.04767215443753367\n",
      "Max gap is 0.08589761521784739\n",
      "Average odds difference is -0.038225\n",
      "Equal opportunity difference is 0.009447\n",
      "Statistical parity difference is -0.057265\n"
     ]
    }
   ],
   "source": [
    "# Skip this if you want to use pre-trained model\n",
    "def extract_weights(run):\n",
    "    data_seed = seeds[run, 0]\n",
    "    \n",
    "    x_train,x_test, y_train, y_test, y_sex_train, y_sex_test, y_race_train, y_race_test,\\\n",
    "         feature_names = get_compas_train_test(random_state = data_seed)\n",
    "    #x_train, x_test = x_train[:, 2:], x_test[:, 2:]\n",
    "\n",
    "    group_train_cross = y_sex_train + 2*y_race_train\n",
    "    group_test_cross = y_sex_test + 2*y_race_test\n",
    "\n",
    "\n",
    "\n",
    "    #### Using 4 protected attributes ####\n",
    "    ## Reduction classifier\n",
    "    eps = 0.05\n",
    "    constraint = EqualizedOdds()\n",
    "    classifier = LogisticRegression(solver='liblinear', fit_intercept=True)\n",
    "    mitigator = ExponentiatedGradient(classifier, constraint, eps=eps, T=50)\n",
    "    mitigator.fit(x_train, y_train, sensitive_features=group_train_cross)\n",
    "    y_pred_mitigated = mitigator.predict(x_test)\n",
    "    print('\\nFair on all test')\n",
    "    _ = group_metrics(y_test, y_pred_mitigated, y_race_test, label_protected=0, label_good=0)\n",
    "\n",
    "    ens_weights = []\n",
    "    coefs = []\n",
    "    intercepts = []\n",
    "\n",
    "    for t, w_t in enumerate(mitigator._weights.index):\n",
    "        if mitigator._weights[w_t] > 0:\n",
    "            coefs.append(mitigator._predictors[t].coef_.flatten())\n",
    "            intercepts.append(mitigator._predictors[t].intercept_[0])\n",
    "            ens_weights.append(mitigator._weights[w_t])\n",
    "\n",
    "    ens_weight = [e.tolist() for e in ens_weights]\n",
    "    coef = [c.tolist() for c in coefs]\n",
    "    intercept = [i.tolist() for i in intercepts]\n",
    "\n",
    "    data = {'ens_weights': ens_weight, 'coefs': coef, 'intercepts': intercept}\n",
    "    return data\n",
    "\n",
    "data = extract_weights(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./reduction/models/data_{seed_data}.txt', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the graph\n",
    "\n",
    "We now build the graph with extracted weights, intercepts and coefficients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = data['coefs']\n",
    "intercept = data['intercepts']\n",
    "weight = data['ens_weights']\n",
    "coefs = [tf.cast(c, dtype = tf.float32) for c in coef]\n",
    "intercepts = [tf.cast(c, dtype = tf.float32) for c in intercept]\n",
    "weights = [tf.cast(c, dtype = tf.float32) for c in weight]\n",
    "\n",
    "def graph_reduction(x):\n",
    "    global coefs, intercepts, weights\n",
    "    n, _ = x.shape\n",
    "    prob = tf.zeros([n, 1], dtype = tf.float32)\n",
    "    for coef, intercept, weight in zip(coefs, intercepts, weights):\n",
    "        coef = tf.reshape(coef, [-1, 1])\n",
    "        model_logit = x @ coef + intercept\n",
    "        model_prob = tf.exp(model_logit) / (1 + tf.exp(model_logit))\n",
    "        prob += model_prob * weight\n",
    "\n",
    "    return tf.concat([1-prob, prob], axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient flow attack and hypothesis testing\n",
    "\n",
    "We now perform gradient flow attack on reduction model. As before, we first define the function for gradient flow attack. For demonstration purpose we perform attact on first 20 sample points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_perturbation(data_point, regularizer = 100, learning_rate = 5e-2, num_steps = 200):\n",
    "    \"\"\"\n",
    "    Calculates ratio between perturbed loss and original loss\n",
    "\n",
    "    parameters: \n",
    "        data_point: tuple of x, y\n",
    "            x: tensor of shape (d, )\n",
    "            y: one-hot encoded tensor of shape (2, )\n",
    "        regularizer (float): regularizer constant for fair metric\n",
    "        learning_rate (float): step size for gradient ascend\n",
    "        num_steps (int): number of steps in gradient ascend\n",
    "\n",
    "    return:\n",
    "        float; ratio of entropy losses for perturbed and original sample\n",
    "    \"\"\"\n",
    "    x, y = data_point\n",
    "    x = tf.reshape(x, (1, -1))\n",
    "    y = tf.reshape(y, (1, -1))\n",
    "    x_start = x\n",
    "    for i in range(num_steps):\n",
    "        with tf.GradientTape() as g:\n",
    "            g.watch(x)\n",
    "            prob = graph_reduction(x)\n",
    "            perturb = utils.unprotected_direction(x-x_start, sensetive_basis)\n",
    "            loss = utils.EntropyLoss(y, prob)  - regularizer  * tf.norm(perturb)**2\n",
    "\n",
    "        gradient = g.gradient(loss, x)\n",
    "        x = x + learning_rate * gradient\n",
    "\n",
    "    return_loss = utils.EntropyLoss(y, graph_reduction(x)) / utils.EntropyLoss(y, graph_reduction(x_start))\n",
    "    \n",
    "    return return_loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "end = 20\n",
    "data_points = zip(x_test[start:end], y_test[start:end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We setup parameters for gradient flow attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularizer = 100\n",
    "learning_rate = 1e-2\n",
    "num_steps = 200\n",
    "sample_perturb = partial(sample_perturbation, regularizer = regularizer, learning_rate = \\\n",
    "                        learning_rate, num_steps = num_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient flow attack is performed on the selected sample points. Along with the lower bound and decision is given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the proposed test, lower bound is 2.6969997419298033 and p-value is 0.0.\n",
      "\n",
      "The test is rejected at a level 0.05 and we conclude the model is \u001b[1;40;47mnot individually fair.\n"
     ]
    }
   ],
   "source": [
    "test_ratio = map(sample_perturb, data_points)\n",
    "test_ratio = list(test_ratio)\n",
    "test_ratio = np.array(test_ratio)\n",
    "test_ratio = test_ratio[np.isfinite(test_ratio)]\n",
    "lower_bound = np.mean(test_ratio) - 1.645*np.std(test_ratio)/np.sqrt(test_ratio.shape[0])\n",
    "t = (np.mean(test_ratio)-1.25)/np.std(test_ratio)\n",
    "t *= np.sqrt(test_ratio.shape[0])\n",
    "pval = 1- norm.cdf(t)\n",
    "print(f'For the proposed test, lower bound is {lower_bound} and\\\n",
    " p-value is {pval}.\\n')\n",
    "decision = 'rejected' if pval < 0.05 else 'not rejected'\n",
    "if pval < 0.05:\n",
    "    print('The test is rejected at a level 0.05 and\\\n",
    " we conclude the model is \\033[1;40;47mnot individually fair.')\n",
    "else:\n",
    "    print('The test is not rejected at a\\\n",
    " level 0.05 and we conclude the model \\033[1;40;47mis individually fair.')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some fairness measures\n",
    "\n",
    "Now we calculate some fairness measures for the fitted model. First we get the predictions on the test data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;40;47mMeasures for gender:\u001b[1;40;0m\n",
      "Accuracy is 0.657197\n",
      "Balanced accuracy is 0.652998\n",
      "Gap RMS is 0.0705225979867558\n",
      "Mean absolute gap is 0.07047441423368517\n",
      "Max gap is 0.07308089945722407\n",
      "Average odds difference is -0.070474\n",
      "Equal opportunity difference is -0.073081\n",
      "Statistical parity difference is -0.018902\n",
      "\n",
      "\u001b[1;40;47mMeasures for race:\u001b[1;40;0m\n",
      "Accuracy is 0.657197\n",
      "Balanced accuracy is 0.652998\n",
      "Gap RMS is 0.06616066577313631\n",
      "Mean absolute gap is 0.058869817533930974\n",
      "Max gap is 0.08906217217987278\n",
      "Average odds difference is 0.030192\n",
      "Equal opportunity difference is 0.089062\n",
      "Statistical parity difference is 0.049304\n",
      "\n",
      "\n",
      "*Accuracy and Balanced accuracy are measuring performance irrespective of the protected attribute.\n"
     ]
    }
   ],
   "source": [
    "prob = graph_reduction(x_test)\n",
    "y_pred = tf.argmax(prob, axis = 1)\n",
    "y_pred = y_pred.numpy()\n",
    "gender = y_sex_test\n",
    "race = y_race_test\n",
    "labels_test = y_test.numpy()[:, 1]\n",
    "\n",
    "print('\\033[1;40;47mMeasures for gender:\\033[1;40;0m')\n",
    "_ = metrics.group_metrics(labels_test, y_pred, gender, label_good=1)\n",
    "\n",
    "print('\\n\\033[1;40;47mMeasures for race:\\033[1;40;0m')\n",
    "_ = metrics.group_metrics(labels_test, y_pred, race, label_good=1)\n",
    "print('\\n\\n*Accuracy and Balanced accuracy are measuring performance irrespective of the protected attribute.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464bit48aa32fa6dba4f1bbd692e320b15fd93"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
