{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597155674965",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import linear_model\n",
    "import utils\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "plt.ioff()\n",
    "import sys\n",
    "from data_preprocess import get_data\n",
    "import json\n",
    "#tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "def sample_perturbation(data_point, regularizer = 20, learning_rate = 3e-2, num_steps = 200):\n",
    "    \"\"\"\n",
    "    Calculates ratio between perturbed loss and original loss\n",
    "\n",
    "    parameters: \n",
    "        data_point: tuple of x, y\n",
    "            x: tensor of shape (d, )\n",
    "            y: one-hot encoded tensor of shape (2, )\n",
    "        regularizer (float): regularizer constant for fair metric\n",
    "        learning_rate (float): step size for gradient ascend\n",
    "        num_steps (int): number of steps in gradient ascend\n",
    "\n",
    "    return:\n",
    "        float; ratio of entropy losses for perturbed and original sample\n",
    "    \"\"\"\n",
    "    x, y = data_point\n",
    "    x = tf.reshape(x, (1, -1))\n",
    "    y = tf.reshape(y, (1, -1))\n",
    "    x_start = x\n",
    "    for i in range(num_steps):\n",
    "        with tf.GradientTape() as g:\n",
    "            g.watch(x)\n",
    "            prob = graph(x)\n",
    "            perturb = utils.unprotected_direction(x-x_start, sensetive_directions)\n",
    "            loss = utils.EntropyLoss(y, prob)  - regularizer  * tf.norm(perturb)**2\n",
    "\n",
    "        gradient = g.gradient(loss, x)\n",
    "        x = x + learning_rate * gradient/((i+1) ** (2/3))\n",
    "        print(loss)\n",
    "\n",
    "    return_loss = utils.EntropyLoss(y, graph(x)) / utils.EntropyLoss(y, graph(x_start))\n",
    "    print('done')\n",
    "    return return_loss.numpy()\n",
    "\n",
    "def SimpleDense(variable):\n",
    "    w, b = variable\n",
    "    w = tf.cast(w, dtype = tf.float32)\n",
    "    b = tf.cast(b, dtype = tf.float32)\n",
    "    return lambda x: tf.matmul(x, w) + b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(5278, 8)\n['sex', 'race', 'priors_count', 'age_cat=25 to 45', 'age_cat=Greater than 45', 'age_cat=Less than 25', 'c_charge_degree=F', 'c_charge_degree=M']\nsex\nrace\n"
    }
   ],
   "source": [
    "seed_data, seed_model = 7751, 43757\n",
    "x_train, x_test, y_train, y_test, _, y_sex_test, y_race_test = get_data(seed_data)\n",
    "\n",
    "\n",
    "\n",
    "sensetive_directions = []\n",
    "protected_regression = linear_model.LogisticRegression(fit_intercept = True)\n",
    "protected_regression.fit(x_test.numpy(), y_sex_test)\n",
    "sensetive_directions.append(protected_regression.coef_.reshape((-1,)))\n",
    "protected_regression.fit(x_test.numpy(), y_race_test)\n",
    "sensetive_directions.append(protected_regression.coef_.reshape((-1,)))\n",
    "sensetive_directions = np.array(sensetive_directions)\n",
    "\n",
    "sensetive_directions = scipy.linalg.orth(sensetive_directions.T).T\n",
    "for i, s in enumerate(sensetive_directions):\n",
    "        #while np.linalg.norm(s) != 1:\n",
    "    s = s/ np.linalg.norm(s)\n",
    "    sensetive_directions[i] = s\n",
    "sensetive_directions = tf.cast(sensetive_directions, dtype = tf.float32)\n",
    "\n",
    "\n",
    "with open(f'models/data_{seed_data}_{seed_model}.txt', 'r') as f:\n",
    "    weight = json.load(f)\n",
    "\n",
    "weights = [np.array(w) for w in weight]\n",
    "\n",
    "def graph(x):\n",
    "    layer1 = SimpleDense([weights[0], weights[1]])\n",
    "    layer2 = SimpleDense([weights[2], weights[3]])\n",
    "    out = tf.nn.relu(layer1(x))\n",
    "    out = layer2(out)\n",
    "    prob = tf.nn.softmax(out)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tf.Tensor(0.5782235, shape=(), dtype=float32)\ntf.Tensor(0.5778041, shape=(), dtype=float32)\ntf.Tensor(0.5692901, shape=(), dtype=float32)\ntf.Tensor(0.5582235, shape=(), dtype=float32)\ntf.Tensor(0.56039625, shape=(), dtype=float32)\ntf.Tensor(0.57307905, shape=(), dtype=float32)\ntf.Tensor(0.58264685, shape=(), dtype=float32)\ntf.Tensor(0.5858533, shape=(), dtype=float32)\ntf.Tensor(0.5868089, shape=(), dtype=float32)\ntf.Tensor(0.5873734, shape=(), dtype=float32)\ntf.Tensor(0.5878782, shape=(), dtype=float32)\ntf.Tensor(0.58835214, shape=(), dtype=float32)\ntf.Tensor(0.5888, shape=(), dtype=float32)\ntf.Tensor(0.5892248, shape=(), dtype=float32)\ntf.Tensor(0.58962965, shape=(), dtype=float32)\ntf.Tensor(0.59001666, shape=(), dtype=float32)\ntf.Tensor(0.5903878, shape=(), dtype=float32)\ntf.Tensor(0.59074444, shape=(), dtype=float32)\ntf.Tensor(0.5910883, shape=(), dtype=float32)\ntf.Tensor(0.59142, shape=(), dtype=float32)\ntf.Tensor(0.5917409, shape=(), dtype=float32)\ntf.Tensor(0.59205174, shape=(), dtype=float32)\ntf.Tensor(0.59235334, shape=(), dtype=float32)\ntf.Tensor(0.59264636, shape=(), dtype=float32)\ntf.Tensor(0.5929314, shape=(), dtype=float32)\ntf.Tensor(0.59320897, shape=(), dtype=float32)\ntf.Tensor(0.59347945, shape=(), dtype=float32)\ntf.Tensor(0.5937436, shape=(), dtype=float32)\ntf.Tensor(0.59400153, shape=(), dtype=float32)\ntf.Tensor(0.5942536, shape=(), dtype=float32)\ntf.Tensor(0.59450024, shape=(), dtype=float32)\ntf.Tensor(0.59474164, shape=(), dtype=float32)\ntf.Tensor(0.59497815, shape=(), dtype=float32)\ntf.Tensor(0.59521, shape=(), dtype=float32)\ntf.Tensor(0.5954373, shape=(), dtype=float32)\ntf.Tensor(0.5956605, shape=(), dtype=float32)\ntf.Tensor(0.5958796, shape=(), dtype=float32)\ntf.Tensor(0.59609497, shape=(), dtype=float32)\ntf.Tensor(0.59630644, shape=(), dtype=float32)\ntf.Tensor(0.5965146, shape=(), dtype=float32)\ntf.Tensor(0.5967193, shape=(), dtype=float32)\ntf.Tensor(0.59692085, shape=(), dtype=float32)\ntf.Tensor(0.59711915, shape=(), dtype=float32)\ntf.Tensor(0.5973145, shape=(), dtype=float32)\ntf.Tensor(0.59750694, shape=(), dtype=float32)\ntf.Tensor(0.5976966, shape=(), dtype=float32)\ntf.Tensor(0.5978836, shape=(), dtype=float32)\ntf.Tensor(0.598068, shape=(), dtype=float32)\ntf.Tensor(0.59825, shape=(), dtype=float32)\ntf.Tensor(0.59842944, shape=(), dtype=float32)\ndone\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1.0355872"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "lr = 5e-2\n",
    "data = x_test[0], y_test[0]\n",
    "sample_perturbation(data, regularizer=50,\\\n",
    "             learning_rate=lr, num_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}