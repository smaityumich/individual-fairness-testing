{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597119562566",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From /Users/smaity/Library/Python/3.7/lib/python/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\nInstructions for updating:\nnon-resource variables are not supported in the long term\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from metrics import group_metrics\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from train_clp_adult import train_fair_nn\n",
    "import tensorflow.compat.v1 as tf\n",
    "import json\n",
    "import sys\n",
    "from data_preprocess import get_data\n",
    "from sklearn import linear_model\n",
    "import compas_data as compas\n",
    "\n",
    "def standardize(x):\n",
    "    return (x - np.mean(x))/np.std(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(5278, 8)\n['sex', 'race', 'priors_count', 'age_cat=25 to 45', 'age_cat=Greater than 45', 'age_cat=Less than 25', 'c_charge_degree=F', 'c_charge_degree=M']\nsex\nrace\n"
    }
   ],
   "source": [
    "seed_data, seed_model = 1, 2\n",
    "# Extracting compas data\n",
    "x_train, x_test, y_train, y_test, y_sex_train, y_sex_test,\\\n",
    "        y_race_train, y_race_test, _ = compas.get_compas_train_test(random_state = seed_data)\n",
    "group_train, group_test = x_train[:, :2], x_test[:, :2]\n",
    "x_train, x_test = x_train[:, 2:], x_test[:, 2:]\n",
    "\n",
    "group_names = ['sex', 'race']\n",
    "\n",
    "\n",
    "one_hot = OneHotEncoder(sparse=False)\n",
    "one_hot.fit(y_train.reshape(-1,1))\n",
    "names_income = one_hot.categories_\n",
    "y_train = one_hot.transform(y_train.reshape(-1,1))\n",
    "y_test = one_hot.transform(y_test.reshape(-1,1))\n",
    "\n",
    "# Standardizing the last four columns\n",
    "for i in range(1, 5):\n",
    "    x_train[:, i] = standardize(x_train[:, i])\n",
    "    x_test[:, i] = standardize(x_test[:, i])\n",
    "\n",
    "    # Calculate the sensitive directions\n",
    "sensetive_directions = []\n",
    "protected_regression = linear_model.LogisticRegression(fit_intercept = True)\n",
    "protected_regression.fit(x_train, y_sex_train)\n",
    "sensetive_directions.append(protected_regression.coef_.reshape((-1,)))\n",
    "protected_regression.fit(x_train, y_race_train)\n",
    "sensetive_directions.append(protected_regression.coef_.reshape((-1,)))\n",
    "sensetive_directions = np.array(sensetive_directions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "objective decreased from 0.693042 to 0.691664; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.693877 to 0.692842; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.694453 to 0.693526; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.692182 to 0.691669; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.692393 to 0.692178; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.692797 to 0.690710; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.692137 to 0.691745; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.692224 to 0.692211; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.692795 to 0.692533; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.692082 to 0.691754; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.694916 to 0.693278; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.692712 to 0.690928; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.691490 to 0.691195; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.694965 to 0.693497; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.693712 to 0.693448; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.692530 to 0.690621; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.691924 to 0.689424; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690460 to 0.690032; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.693401 to 0.692498; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.692702 to 0.692023; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.692153 to 0.692043; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.689981 to 0.689185; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690514 to 0.690279; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.693526 to 0.692132; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690982 to 0.689029; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.692881 to 0.692307; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690421 to 0.689837; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.691206 to 0.691102; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.693251 to 0.692325; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.692501 to 0.691438; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690286 to 0.687658; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.691757 to 0.691646; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.693106 to 0.692402; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.693302 to 0.693169; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.691360 to 0.689989; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.691519 to 0.690855; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690840 to 0.689945; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.691116 to 0.690443; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.691004 to 0.690457; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.692686 to 0.692530; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.691305 to 0.688304; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.691791 to 0.691054; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.692293 to 0.691274; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.691780 to 0.688326; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.692828 to 0.691656; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.691255 to 0.690876; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.692258 to 0.691141; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690245 to 0.687229; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.691580 to 0.691224; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690171 to 0.688498; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.692416 to 0.690182; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.691678 to 0.690943; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.691965 to 0.691619; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.692595 to 0.691389; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.691761 to 0.691031; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690861 to 0.688361; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.693637 to 0.693588; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690508 to 0.690070; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.691243 to 0.690384; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.692712 to 0.691530; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690268 to 0.690006; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.692530 to 0.692184; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.691173 to 0.689946; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.691076 to 0.689715; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690820 to 0.689900; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.693175 to 0.692831; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.693246 to 0.691311; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.692365 to 0.690460; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690005 to 0.689619; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690230 to 0.689676; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.693030 to 0.691875; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.692424 to 0.691714; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.691449 to 0.691316; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.692642 to 0.691604; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690566 to 0.689615; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.691541 to 0.691310; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690712 to 0.689751; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.691565 to 0.688201; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690199 to 0.689254; resetting the attack\nReal and fair distances (max/min/mean):\n3570.4347743409508 46.67233662734618 1468.0700969519899\n0.000110053035 3.684736e-05 0.000101877486\nCounter success count is -1\nEpoch 3000 train accuracy 0.497631; loss 0.691744; lambda is 0.000010\nEpoch 3000 test accuracy 0.472538\nFAILED attacks: subspace 179; full 0; Nans after attack 0\nLoss clean 0.691779; subspace 0.694816; adv 0.695788\nWARNING: subspace attack failed: objective decreased from 0.689824 to 0.689394; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.692968 to 0.692384; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.689433 to 0.688341; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.691218 to 0.691101; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.689237 to 0.689027; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690814 to 0.690584; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.693233 to 0.691857; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.695629 to 0.695035; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690166 to 0.688110; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.689005 to 0.688549; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.691630 to 0.689294; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.686908 to 0.685698; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.692885 to 0.691935; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.688816 to 0.688233; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.692797 to 0.691555; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.691050 to 0.690998; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.689826 to 0.688771; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.689263 to 0.689139; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690401 to 0.689941; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.688192 to 0.687165; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690246 to 0.688656; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690688 to 0.688138; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.689266 to 0.687145; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.691814 to 0.690789; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690901 to 0.689236; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.692642 to 0.692182; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.692214 to 0.692083; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.689760 to 0.689161; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.688645 to 0.688494; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.688041 to 0.686945; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690258 to 0.689990; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.692227 to 0.692157; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.692530 to 0.691568; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.689026 to 0.687817; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.691974 to 0.691608; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690442 to 0.690356; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.691607 to 0.690059; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.688091 to 0.687852; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.689832 to 0.689798; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.687461 to 0.687274; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.688635 to 0.684480; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690543 to 0.690302; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690906 to 0.690315; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.691501 to 0.688154; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690782 to 0.690670; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.691911 to 0.691836; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690446 to 0.689771; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.689073 to 0.688971; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690878 to 0.689080; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.693393 to 0.692901; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.689506 to 0.689065; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690611 to 0.689479; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.689158 to 0.688169; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690413 to 0.689153; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690235 to 0.688790; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.687252 to 0.686999; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.692150 to 0.691575; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.689571 to 0.688794; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.689021 to 0.689005; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.691153 to 0.689240; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.688081 to 0.688069; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690850 to 0.690037; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.688129 to 0.686698; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.691205 to 0.690696; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.692853 to 0.691227; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.689656 to 0.689195; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.686816 to 0.685462; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.692301 to 0.691869; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690677 to 0.690507; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690961 to 0.689211; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.686435 to 0.684353; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.689129 to 0.689024; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690195 to 0.689884; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.687655 to 0.687461; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.694692 to 0.691504; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.686341 to 0.685253; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.687137 to 0.686821; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.688336 to 0.686747; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.688919 to 0.688331; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.688156 to 0.687528; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.688574 to 0.687886; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.687324 to 0.687086; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.687331 to 0.687099; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.683830 to 0.683008; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.688076 to 0.687674; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690441 to 0.688116; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.688463 to 0.686526; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690735 to 0.689133; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.691232 to 0.690918; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.689277 to 0.688158; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.690280 to 0.689791; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.691038 to 0.687653; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.687113 to 0.687014; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.689401 to 0.687127; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.687637 to 0.687609; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.686897 to 0.686585; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.687335 to 0.686046; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.688949 to 0.686258; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.689526 to 0.688977; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.689370 to 0.686824; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.687390 to 0.687384; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.687955 to 0.687507; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.684750 to 0.682612; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.691539 to 0.688083; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.689440 to 0.688041; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.689997 to 0.687577; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.691101 to 0.689270; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.692600 to 0.690236; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.687964 to 0.687401; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.686832 to 0.685986; resetting the attack\nWARNING: subspace attack failed: objective decreased from 0.693102 to 0.692130; resetting the attack\nReal and fair distances (max/min/mean):\n4509.161337171704 83.73578885234537 1637.7020247692112\n0.000110053035 3.684736e-05 0.000101877486\nCounter success count is -1\nEpoch 3999 train accuracy 0.545476; loss 0.688767; lambda is 0.000010\nEpoch 3999 test accuracy 0.50947\nFAILED attacks: subspace 290; full 0; Nans after attack 0\nLoss clean 0.686025; subspace 0.691157; adv 0.692147\n\nFinal train accuracy 0.545476\nFinal test accuracy 0.50947\nFinal lambda 0.000010\n"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "fair_info = [group_train, group_test, group_names, sensetive_directions]\n",
    "weights, train_logits, test_logits, _, variables = train_fair_nn(x_train,\\\n",
    "     y_train,tf_prefix='sensr', adv_epoch_full=50, l2_attack=0.0001,\\\n",
    "         adv_epoch=10, ro=0.001, adv_step=10., plot=False,\\\n",
    "        fair_info=fair_info,balance_batch=True,\\\n",
    "            X_test = x_test, X_test_counter=None,\\\n",
    "                y_test = y_test, lamb_init=2.,\\\n",
    "                n_units=[100], l2_reg=0, epoch=4000,\\\n",
    "                batch_size=1000, lr=1e-4, lambda_clp=0.,\\\n",
    "            fair_start=0., counter_init=False, seed=seed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Gender:\nAccuracy is 0.509470\nBalanced accuracy is 0.518150\nGap RMS is 0.147684461869415\nMean absolute gap is 0.10483439733726196\nMax gap is 0.2088557865444427\nAverage odds difference is 0.104021\nEqual opportunity difference is -0.000813\nStatistical parity difference is 0.129000\n\nRace:\nAccuracy is 0.509470\nBalanced accuracy is 0.518150\nGap RMS is 0.11472973115977106\nMean absolute gap is 0.11467600472884776\nMax gap is 0.11818672423097676\nAverage odds difference is 0.114676\nEqual opportunity difference is 0.118187\nStatistical parity difference is 0.117180\n"
    }
   ],
   "source": [
    "print('Gender:')\n",
    "_ = group_metrics(y_test[:,1], test_logits.argmax(axis=1), group_test[:,0],\\\n",
    "     label_protected=0,label_good=1)\n",
    "print('\\nRace:')\n",
    "_ = group_metrics(y_test[:,1], test_logits.argmax(axis=1), group_test[:,1],\\\n",
    "     label_protected=0, label_good=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0., 1.],\n       [1., 0.],\n       [0., 1.],\n       ...,\n       [0., 1.],\n       [1., 0.],\n       [1., 0.]])"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[ 0.10920897,  0.32617792],\n       [ 0.05807625,  0.07834068],\n       [-0.08675189,  0.14817993],\n       ...,\n       [ 0.09307206,  0.318889  ],\n       [-0.11403552,  0.12835373],\n       [ 0.09701891, -0.0232924 ]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "test_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([1, 1, 1, ..., 1, 1, 0])"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "test_logits.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred, y_protected = y_test[:, 1], test_logits.argmax(axis=1), group_test[:, 0]\n",
    "label_protected,label_good= 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy is 0.509470\nBalanced accuracy is 0.517146\nGap RMS is nan\nMean absolute gap is nan\nMax gap is nan\nAverage odds difference is nan\nEqual opportunity difference is nan\nStatistical parity difference is nan\n"
    }
   ],
   "source": [
    "idx_prot = np.where(y_protected == label_protected)[0]\n",
    "idx_priv = np.where(y_protected != label_protected)[0]\n",
    "idx_good_class = np.where(y_true == label_good)[0]\n",
    "idx_pred_good_class = np.where(y_pred == label_good)[0]\n",
    "idx_bad_class = np.where(y_true != label_good)[0]\n",
    "idx_pred_bad_class = np.where(y_pred != label_good)[0]\n",
    "correct = y_true==y_pred\n",
    "\t\n",
    "TPR_prot = correct[np.intersect1d(idx_good_class, idx_prot)].mean()\n",
    "FP_prot = (1-correct[np.intersect1d(idx_pred_good_class, idx_prot)]).sum()\n",
    "FPR_prot = FP_prot/len(np.intersect1d(idx_bad_class, idx_prot))\n",
    "TPR_priv = correct[np.intersect1d(idx_good_class, idx_priv)].mean()\n",
    "FP_priv = (1-correct[np.intersect1d(idx_pred_good_class, idx_priv)]).sum()\n",
    "FPR_priv = FP_priv/len(np.intersect1d(idx_bad_class, idx_priv))\n",
    "    \n",
    "accuracy = correct.mean()\n",
    "print('Accuracy is %f' % accuracy)\n",
    "    \n",
    "bal_acc = (correct[idx_good_class].mean() + correct[idx_bad_class].mean())/2\n",
    "print('Balanced accuracy is %f' % bal_acc)\n",
    "    \n",
    "    # TPR_bad_prot = correct[np.intersect1d(idx_bad_class, idx_prot)].mean()\n",
    "    # TPR_bad_priv = correct[np.intersect1d(idx_bad_class, idx_priv)].mean()\n",
    "gaps = np.array([np.abs(TPR_prot - TPR_priv), np.abs(FPR_prot - FPR_priv)])\n",
    "gap_rms = np.sqrt((gaps**2).mean())\n",
    "mean_gap = gaps.mean()\n",
    "max_gap = gaps.max()\n",
    "print('Gap RMS is', gap_rms)\n",
    "print('Mean absolute gap is', mean_gap)\n",
    "print('Max gap is', max_gap)\n",
    "    \n",
    "average_odds_difference = ((TPR_prot - TPR_priv) + (FPR_prot - FPR_priv))/2\n",
    "print('Average odds difference is %f' % average_odds_difference)\n",
    "    \n",
    "equal_opportunity_difference = TPR_prot - TPR_priv\n",
    "print('Equal opportunity difference is %f' % equal_opportunity_difference)\n",
    "    \n",
    "statistical_parity_difference =\\\n",
    "     (y_pred[idx_prot]==label_good).mean()- (y_pred[idx_priv]==label_good).mean()\n",
    "print('Statistical parity difference is %f' % statistical_parity_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([nan, nan])"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "nan"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "TPR_prot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([], dtype=int64)"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "idx_prot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([ 1.94544287, -0.70866907, -0.30034415, ...,  1.74128041,\n       -0.50450661, -0.70866907])"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "y_protected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "starts = np.arange(0, 901, 100)\n",
    "ends = np.arange(100, 1001, 100)\n",
    "expts = ['sensr', 'reduction', 'baseline', 'baseline_bal'] \n",
    "data_index = range(ends.shape[0])\n",
    "iteration = range(10)\n",
    "lrs = [2e-3, 5e-3, 1e-2]\n",
    "\n",
    "a = itertools.product(expts, data_index, iteration, lrs)\n",
    "b = [i for i in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printf(n):\n",
    "    n = n* 10\n",
    "    print(f'{b[n + 3]} {b[n+2]} {b[n+4]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "('sensr', 0, 4, 0.005) ('sensr', 0, 4, 0.002) ('sensr', 0, 4, 0.01)\n('sensr', 1, 4, 0.005) ('sensr', 1, 4, 0.002) ('sensr', 1, 4, 0.01)\n('sensr', 2, 4, 0.005) ('sensr', 2, 4, 0.002) ('sensr', 2, 4, 0.01)\n('sensr', 3, 4, 0.005) ('sensr', 3, 4, 0.002) ('sensr', 3, 4, 0.01)\n('sensr', 4, 4, 0.005) ('sensr', 4, 4, 0.002) ('sensr', 4, 4, 0.01)\n('sensr', 5, 4, 0.005) ('sensr', 5, 4, 0.002) ('sensr', 5, 4, 0.01)\n('sensr', 6, 4, 0.005) ('sensr', 6, 4, 0.002) ('sensr', 6, 4, 0.01)\n('sensr', 7, 4, 0.005) ('sensr', 7, 4, 0.002) ('sensr', 7, 4, 0.01)\n('sensr', 8, 4, 0.005) ('sensr', 8, 4, 0.002) ('sensr', 8, 4, 0.01)\n('sensr', 9, 4, 0.005) ('sensr', 9, 4, 0.002) ('sensr', 9, 4, 0.01)\n('reduction', 0, 1, 0.002) ('reduction', 0, 0, 0.01) ('reduction', 0, 1, 0.005)\n"
    }
   ],
   "source": [
    "for i in [1, 4, 7, 10, 13, 16, 19, 22, 25, 28, 30]:\n",
    "    printf(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "starts = np.arange(0, 901, 10)\n",
    "ends = np.arange(10, 1001, 10)\n",
    "expts = ['sensr', 'reduction', 'baseline', 'project'] \n",
    "data_index = range(ends.shape[0])\n",
    "iteration = range(10)\n",
    "lrs = [2e-3, 5e-3, 1e-2]\n",
    "\n",
    "a = itertools.product(expts, data_index, iteration, lrs)\n",
    "b = [i for i in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "('sensr', 2, 4, 0.01)"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "b[74]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import linear_model\n",
    "import utils\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "plt.ioff()\n",
    "import sys\n",
    "from data_preprocess import get_data\n",
    "#tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "def sample_perturbation(data_point, regularizer = 20, learning_rate = 3e-2, num_steps = 200):\n",
    "    \"\"\"\n",
    "    Calculates ratio between perturbed loss and original loss\n",
    "\n",
    "    parameters: \n",
    "        data_point: tuple of x, y\n",
    "            x: tensor of shape (d, )\n",
    "            y: one-hot encoded tensor of shape (2, )\n",
    "        regularizer (float): regularizer constant for fair metric\n",
    "        learning_rate (float): step size for gradient ascend\n",
    "        num_steps (int): number of steps in gradient ascend\n",
    "\n",
    "    return:\n",
    "        float; ratio of entropy losses for perturbed and original sample\n",
    "    \"\"\"\n",
    "    x, y = data_point\n",
    "    x = tf.reshape(x, (1, -1))\n",
    "    y = tf.reshape(y, (1, -1))\n",
    "    x_start = x\n",
    "    for i in range(num_steps):\n",
    "        with tf.GradientTape() as g:\n",
    "            g.watch(x)\n",
    "            prob = graph(x)\n",
    "            perturb = utils.unprotected_direction(x-x_start, sensetive_directions)\n",
    "            loss = utils.EntropyLoss(y, prob)  - regularizer  * tf.norm(perturb)**2\n",
    "\n",
    "        gradient = g.gradient(loss, x)\n",
    "        x = x + learning_rate * gradient/(i ** (2/3))\n",
    "\n",
    "    return_loss = utils.EntropyLoss(y, graph(x)) / utils.EntropyLoss(y, graph(x_start))\n",
    "    print('done')\n",
    "    return return_loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt, d, i, lr = b[74]\n",
    "start = starts[d]\n",
    "end = ends[d]\n",
    "np.random.seed(1)\n",
    "seeds = np.load('../seeds.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_seed = seeds[i, 0]\n",
    "expt_seed = seeds[i, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(5278, 8)\n['sex', 'race', 'priors_count', 'age_cat=25 to 45', 'age_cat=Greater than 45', 'age_cat=Less than 25', 'c_charge_degree=F', 'c_charge_degree=M']\nsex\nrace\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-b7ee1222f89f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msensetive_directions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0msensetive_directions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2475\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2476\u001b[0m                 \u001b[0msqnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2477\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2478\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2479\u001b[0m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "x_train, x_test, y_train, y_test, _, y_sex_test, y_race_test = get_data(data_seed)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sensetive_directions = []\n",
    "protected_regression = linear_model.LogisticRegression(fit_intercept = True)\n",
    "protected_regression.fit(x_test.numpy(), y_sex_test)\n",
    "sensetive_directions.append(protected_regression.coef_.reshape((-1,)))\n",
    "protected_regression.fit(x_test.numpy(), y_race_test)\n",
    "sensetive_directions.append(protected_regression.coef_.reshape((-1,)))\n",
    "sensetive_directions = np.array(sensetive_directions)\n",
    "\n",
    "sensetive_directions = scipy.linalg.orth(sensetive_directions.T).T\n",
    "for i, s in enumerate(sensetive_directions):\n",
    "    #while np.linalg.norm(s) != 1:\n",
    "    s = s/ np.linalg.norm(s)\n",
    "    sensetive_directions[i] = s\n",
    "\n",
    "sensetive_directions = tf.cast(sensetive_directions, dtype = tf.float32)\n",
    "\n",
    "\n",
    "\n",
    "with open(f'models/data_{data_seed}_{expt_seed}.txt', 'r') as f:\n",
    "    weight = json.load(f)\n",
    "\n",
    "weights = [np.array(w) for w in weight]\n",
    "\n",
    "def graph(x):\n",
    "    layer1 = SimpleDense([weights[0], weights[1]])\n",
    "    layer2 = SimpleDense([weights[2], weights[3]])\n",
    "    out = tf.nn.relu(layer1(x))\n",
    "    out = layer2(out)\n",
    "    prob = tf.nn.softmax(out)\n",
    "    return prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(20609, 49100)"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "data_seed, expt_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}